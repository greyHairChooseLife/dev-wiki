# model serving framework



## python 기반


1. **FastAPI**
   - 최신 Python 비동기 웹 프레임워크.
   - 빠른 개발, 자동 문서화(Swagger UI), 비동기 지원.
   - AI/ML 모델 서빙에 많이 사용됨.
   - S3에서 파일 다운로드는 `boto3` 라이브러리로 쉽게 구현 가능.

2. **Flask**
   - 경량 웹 프레임워크.
   - 간단한 API 서버에 적합.
   - FastAPI보다 느리지만, 사용법이 매우 쉽고 자료가 많음.

3. **TorchServe / TensorFlow Serving**
   - PyTorch, TensorFlow 모델을 위한 공식 서빙 프레임워크.
   - REST API 제공.
   - 복잡한 배포, 대규모 서비스에 적합.
   - 커스텀 로직(예: S3에서 직접 가중치 로딩)이 필요하면 FastAPI/Flask가 더 유연함.


### 표준화된 방식

**TorchServe**와 **TensorFlow Serving** 같은 표준화된 모델 서빙 프레임워크가 널리 쓰이는 이유는 다음과 같은 장점 때문입니다.



**1. 일관된 API와 관리**
- REST/gRPC 등 표준화된 API 제공 → 다양한 언어/플랫폼에서 쉽게 연동 가능
- 모델 버전 관리, 롤링 업데이트, A/B 테스트 등 운영에 필요한 기능 내장

**2. 성능 최적화**
- 배치 추론, 멀티스레딩, GPU 지원 등 고성능 추론에 최적화
- 대량 요청 처리, 지연 시간 최소화 등 실서비스에 적합

**3. 운영 자동화**
- 헬스 체크, 로깅, 모니터링, 자동 스케일링 등 운영에 필요한 기능 제공
- Kubernetes 등 클라우드 환경과의 연동이 용이

**4. 보안 및 신뢰성**
- 검증된 프레임워크로, 보안/안정성 측면에서 신뢰할 수 있음
- 커뮤니티와 기업의 지원, 업데이트가 활발함

**5. 표준화된 배포**
- 여러 팀/서비스에서 동일한 방식으로 모델을 배포하고 관리할 수 있음
- DevOps, MLOps 파이프라인에 쉽게 통합 가능
